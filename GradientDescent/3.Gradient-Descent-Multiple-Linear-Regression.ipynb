{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多元线性回归中的梯度下降法\n",
    "\n",
    "其中\n",
    "$$-\\eta\\frac{dJ}{d\\theta}$$\n",
    "应变为\n",
    "$$-\\eta\\nabla J$$\n",
    "其中\n",
    "$$\\nabla J = (\\frac{\\partial J}{\\partial \\theta_0}, \\frac{\\partial J}{\\partial \\theta_1}, \\ldots ,\\frac{\\partial J}{\\partial \\theta_n})$$\n",
    "梯度代表方向，对应J增大最快的方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标化简\n",
    "\n",
    "线性回归目标：使\n",
    "$$\\sum_{i=1}^m (y^{(i)} - \\hat{y}^{(i)})^2$$\n",
    "尽可能小\n",
    "\n",
    "$$\\hat{y}^{(i)} = \\theta_0 + \\theta_1 X_1^{(i)} + \\theta_2 X_2^{(i)} + \\ldots + \\theta_n X_n^{(i)}$$\n",
    "\n",
    "则目标可变为：使\n",
    "$$\\sum_{i=1}^m (y^{(i)} - \\theta_0 - \\theta_1 X_1^{(i)} - \\theta_2 X_2^{(i)} - \\ldots -  \\theta_n X_n^{(i)})^2$$\n",
    "尽可能小\n",
    "\n",
    "即上述函数对应损失函数J\n",
    "\n",
    "$$\\nabla J(\\theta) = \\begin{pmatrix}\n",
    "\\frac{\\partial J}{\\partial \\theta_0} \\\\\\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_1} \\\\\\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_2} \\\\\\\\\n",
    "\\ldots \\\\\\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_n}\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "\\sum_{i=1}^m 2(y^{(i)} - X_b^{(i)}\\theta) \\cdot (-1)\\\\\\\\\n",
    "\\sum_{i=1}^m 2(y^{(i)} - X_b^{(i)}\\theta) \\cdot (-X^{(i)}_1) \\\\\\\\\n",
    "\\sum_{i=1}^m 2(y^{(i)} - X_b^{(i)}\\theta) \\cdot (-X^{(i)}_2) \\\\\\\\\n",
    "\\ldots \\\\\\\\\n",
    "\\sum_{i=1}^m 2(y^{(i)} - X_b^{(i)}\\theta) \\cdot (-X^{(i)}_n)\n",
    "\\end{pmatrix}\n",
    "= 2 \\cdot \\begin{pmatrix}\n",
    "\\sum_{i=1}^m (X_b^{(i)}\\theta - y^{(i)}) \\\\\\\\\n",
    "\\sum_{i=1}^m (X_b^{(i)}\\theta - y^{(i)}) \\cdot X^{(i)}_1 \\\\\\\\\n",
    "\\sum_{i=1}^m (X_b^{(i)}\\theta - y^{(i)}) \\cdot X^{(i)}_2 \\\\\\\\\n",
    "\\ldots \\\\\\\\\n",
    "\\sum_{i=1}^m (X_b^{(i)}\\theta - y^{(i)}) \\cdot X^{(i)}_n\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "但是此时梯度会和样本数量m相关，我们更改损失函数为下述方式(MSE)：\n",
    "$$\\frac{1}{m}\\sum_{i=1}^m (y^{(i)} - \\hat{y}^{(i)})^2$$\n",
    "\n",
    "则：\n",
    "$$\\nabla J(\\theta) = \n",
    "\\frac{2}{m} \\cdot \\begin{pmatrix}\n",
    "\\sum_{i=1}^m (X_b^{(i)}\\theta - y^{(i)}) \\\\\\\\\n",
    "\\sum_{i=1}^m (X_b^{(i)}\\theta - y^{(i)}) \\cdot X^{(i)}_1 \\\\\\\\\n",
    "\\sum_{i=1}^m (X_b^{(i)}\\theta - y^{(i)}) \\cdot X^{(i)}_2 \\\\\\\\\n",
    "\\ldots \\\\\\\\\n",
    "\\sum_{i=1}^m (X_b^{(i)}\\theta - y^{(i)}) \\cdot X^{(i)}_n\n",
    "\\end{pmatrix}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
