{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归的损失函数\n",
    "\n",
    "逻辑回归：\n",
    "\n",
    "$$\\hat{p} = \\sigma(\\theta^T \\cdot x_b) = \\frac{1}{1 + e^{-\\theta^T \\cdot x_b}}$$\n",
    "\n",
    "$$\\hat{y} = \\begin{cases}\n",
    "1, \\quad \\hat{p} \\geq 0.5 \\\\\\\\\n",
    "0, \\quad \\hat{p} \\leq 0.5\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "则损失函数为：\n",
    "\n",
    "$$cost = \\begin{cases}\n",
    "如果y=1,p越小,cost越大\\\\\\\\\n",
    "如果y=0,p越大,cost越大\n",
    "\\end{cases}$$\n",
    "\n",
    "我们可以用使用这种函数作为损失函数\n",
    "\n",
    "$$cost=\\begin{cases}\n",
    "-log(\\hat{p}), \\quad if \\quad y=1\\\\\\\\\n",
    "-log(1-\\hat{p}), \\quad if \\quad y=0\n",
    "\\end{cases}$$\n",
    "\n",
    "可以推导为：\n",
    "\n",
    "$$cost=-ylog(\\hat{p})-(1-y)log(1-\\hat{p}) \\qquad其中 (y \\in \\{0,1\\})$$\n",
    "\n",
    "则,对应m个样本\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^my^{(i)}log(\\hat{p}^{(i)}) + (1-y^{(i)})log(1-\\hat{p}^{(i)})$$\n",
    "\n",
    "$$\\hat{p}^{(i)} = \\sigma(x_b^{(i)} \\theta) = \\frac{1}{1 + e^{-x_b^{(i)} \\theta}}$$\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^my^{(i)}log(\\sigma(x_b^{(i)} \\theta)) + (1-y^{(i)})log(1-\\sigma(x_b^{(i)} \\theta))$$\n",
    "\n",
    "**对于这个算式，没有公式解，只能使用梯度下降法求解**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归损失函数的梯度\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^my^{(i)}log(\\sigma(x_b^{(i)} \\theta)) + (1-y^{(i)})log(1-\\sigma(x_b^{(i)} \\theta))$$\n",
    "\n",
    "首先对sigmoid函数求导\n",
    "\n",
    "$$\\sigma(t) = \\frac{1}{1+e^{-t}} = (1+e^{-t})^{-1} \\qquad \\sigma(t)^{'}=(1+e^{-t})^{-2} \\cdot e^{-t}$$\n",
    "\n",
    "然后对$log\\sigma(t)$求导\n",
    "\n",
    "$$(log\\sigma(t))^{'}=\\frac{1}{\\sigma(t)} \\cdot \\sigma(t)^{'}=(1+e^{-t})^{-1} \\cdot e^{-t} = \\frac{e^{-t}}{1+e^{-t}} = \\frac{1+e^{-t}-1}{1+e^{-t}} = 1-\\frac{1}{1+e^{-t}}$$\n",
    "\n",
    "$$(log\\sigma(t))^{'} = 1-\\sigma(t)$$\n",
    "\n",
    "**所以**\n",
    "\n",
    "$$\\frac{d(y^{(i)}log\\sigma(x_b^{(i)} \\theta))}{d\\theta_j} = y^{(i)}(1-\\sigma((x_b^{(i)} \\theta)) \\cdot X_j^{(i)} = y^{(i)}X_j^{(i)}-y^{(i)}\\sigma(X_b^{(i)}\\theta) \\cdot X_j^{(i)}$$\n",
    "\n",
    "然后对$log(1-\\sigma(t))$求导\n",
    "\n",
    "$$(log(1-\\sigma(t)))^{'}=\\frac{1}{1-\\sigma(t)} \\cdot (-1) \\cdot \\sigma(t)^{'} = -\\frac{1}{1-\\sigma(t)} \\cdot (1+e^{-t})^{-2} \\cdot e^{-t}$$\n",
    "\n",
    "其中\n",
    "\n",
    "$$-\\frac{1}{1-\\sigma(t)} = -\\frac{1}{\\frac{1+e^{-t}}{1+e^{-t}} - \\frac{1}{1+e^{-t}}} = -\\frac{1+e^{-t}}{e^{-t}}$$\n",
    "\n",
    "则\n",
    "\n",
    "$$(log(1-\\sigma(t)))^{'}= -(1+e^{-t})^{-1} = -\\sigma(t)$$\n",
    "\n",
    "**所以**\n",
    "\n",
    "$$\\frac{d((1-y^{(i)})log(1-\\sigma(x_b^{(i)} \\theta)))}{d(\\theta_j)} = (1-y^{(i)}) \\cdot (-\\sigma(x_b^{(i)} \\theta)) \\cdot X_j^{(i)} = -\\sigma(X_b^{(i)}\\theta) \\cdot X_j^{(i)} + y^{(i)}\\sigma(X_b^{(i)}\\theta) \\cdot X_j^{(i)}$$\n",
    "\n",
    "**所以**\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^m(\\sigma(X_b^{(i)}\\theta)-y^{(i)}) X_j^{(i)} = \\frac{1}{m}\\sum_{i=1}^m(\\hat{p}^{(i)}-y^{(i)}) X_j^{(i)}$$\n",
    "\n",
    "**所以，梯度：**\n",
    "\n",
    "$$\\nabla J(\\theta) = \\begin{pmatrix}\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_0} \\\\\\\\\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_1} \\\\\\\\\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_2} \\\\\\\\\n",
    "\\ldots \\\\\\\\\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_n} \\\\\\\\\n",
    "\\end{pmatrix} = \\frac{1}{m}\\begin{pmatrix}\n",
    "\\sum_{i=1}^m(\\sigma(X_b^{(i)}\\theta)-y^{(i)}) \\\\\\\\\n",
    "\\sum_{i=1}^m(\\sigma(X_b^{(i)}\\theta)-y^{(i)}) \\cdot X_1^{(i)}\\\\\\\\\n",
    "\\sum_{i=1}^m(\\sigma(X_b^{(i)}\\theta)-y^{(i)}) \\cdot X_2^{(i)}\\\\\\\\\n",
    "\\ldots \\\\\\\\\n",
    "\\sum_{i=1}^m(\\sigma(X_b^{(i)}\\theta)-y^{(i)}) \\cdot X_n^{(i)}\\\\\\\\\n",
    "\\end{pmatrix} = \\frac{1}{m}\\begin{pmatrix}\n",
    "\\sum_{i=1}^m(\\hat{p}^{(i)}-y^{(i)}) \\\\\\\\\n",
    "\\sum_{i=1}^m(\\hat{p}^{(i)}-y^{(i)}) \\cdot X_1^{(i)}\\\\\\\\\n",
    "\\sum_{i=1}^m(\\hat{p}^{(i)}-y^{(i)}) \\cdot X_2^{(i)}\\\\\\\\\n",
    "\\ldots \\\\\\\\\n",
    "\\sum_{i=1}^m(\\hat{p}^{(i)}-y^{(i)}) \\cdot X_n^{(i)}\\\\\\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "**向量化**\n",
    "\n",
    "$$\\nabla J(\\theta) = \\frac{1}{m} \\cdot X_b^T \\cdot(\\sigma(X_b\\theta)-y)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
