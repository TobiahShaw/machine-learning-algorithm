{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 偏差方差权衡\n",
    "\n",
    "**偏差**：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，如下图第二行所示。\n",
    "\n",
    "**方差**：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，如下图右列所示。\n",
    "\n",
    "![bias and variance](..\\img\\bias-and-variance.png)\n",
    "\n",
    "方差，是形容数据分散程度的，算是“无监督的”，客观的指标，偏差，形容数据跟我们期望的中心差得有多远，算是“有监督的”，有人的知识参与的指标。\n",
    "\n",
    "## 模型误差\n",
    "\n",
    "模型误差 = 偏差（Bias） + 方差（Variance） + 不可避免的误差\n",
    "\n",
    "**导致偏差的主要原因**：\n",
    "\n",
    "对问题本身的假设不正确！\n",
    "\n",
    "如：非线性数据使用线性回归\n",
    "\n",
    "最主要的原因：欠拟合underfitting\n",
    "\n",
    "其他原因：使用的特征和目标高度不相关\n",
    "\n",
    "**导致方差的主要原因**：\n",
    "\n",
    "数据的一点点扰动都会较大的影响模型。\n",
    "\n",
    "通常原因：使用的模型太复杂，过拟合。\n",
    "\n",
    "如高阶多项式回归。\n",
    "\n",
    "## 偏差和方差\n",
    "\n",
    "有一些算法天生是高方差的算法。如kNN。\n",
    "\n",
    "非参数学习通常都是高方差算法。因为不对数据进行任何假设。\n",
    "\n",
    "有一些算法天生是高偏差的算法。如线性回归。\n",
    "\n",
    "参数学习通常都是高偏差算法。因为对数据具有极强的假设。\n",
    "\n",
    "大多数算法具有相应的参数，可以调整偏差和方差。\n",
    "\n",
    "如：\n",
    "\n",
    "kNN 中的 k ；\n",
    "\n",
    "线性回归中使用多项式回归。\n",
    "\n",
    "**偏差和方差通常是矛盾的**\n",
    "\n",
    "**降低偏差，会提高方差**\n",
    "\n",
    "**降低方差，会提高偏差**\n",
    "\n",
    "机器学习的主要挑战，来自于方差！（算法层次）\n",
    "\n",
    "**解决高方差的通常手段**：\n",
    "\n",
    "1. 降低模型复杂度\n",
    "2. 减少数据维度、降噪\n",
    "3. 增加样本数\n",
    "4. 使用验证集\n",
    "5. 模型正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
